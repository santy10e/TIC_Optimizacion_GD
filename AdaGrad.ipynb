{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nueva ley económica el gobierno presenta un pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>presidente el psoe se erigió como gran enemigo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>boluarte se aferra al bloqueo de un cgpj de ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sigue en directo el debate electoral entre los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>15 de abril de 2024 se celebra el día internac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>0</td>\n",
       "      <td>iniciativa vers per catalunya cs y coalición c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11138</th>\n",
       "      <td>0</td>\n",
       "      <td>cristina narbona promete despenalizar la eutan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>1</td>\n",
       "      <td>òmnium cree que cristina narbona debe aceptar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11140</th>\n",
       "      <td>0</td>\n",
       "      <td>cristina narbona se reivindica ante la extrema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11141</th>\n",
       "      <td>0</td>\n",
       "      <td>la extravagante respuesta del gobierno a un di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11142 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                                              Texto\n",
       "0          0  nueva ley económica el gobierno presenta un pr...\n",
       "1          1  presidente el psoe se erigió como gran enemigo...\n",
       "2          0  boluarte se aferra al bloqueo de un cgpj de ma...\n",
       "3          1  sigue en directo el debate electoral entre los...\n",
       "4          0  15 de abril de 2024 se celebra el día internac...\n",
       "...      ...                                                ...\n",
       "11137      0  iniciativa vers per catalunya cs y coalición c...\n",
       "11138      0  cristina narbona promete despenalizar la eutan...\n",
       "11139      1  òmnium cree que cristina narbona debe aceptar ...\n",
       "11140      0  cristina narbona se reivindica ante la extrema...\n",
       "11141      0  la extravagante respuesta del gobierno a un di...\n",
       "\n",
       "[11142 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (accuracy_score, f1_score, \n",
    "                             precision_score, recall_score, \n",
    "                             confusion_matrix, ConfusionMatrixDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Verificar si hay GPU disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Función para preprocesar texto\n",
    "def preprocess_text(text_series):\n",
    "    text_series = text_series.str.replace(r'http\\S+', '', regex=True)  # Eliminar URLs\n",
    "    text_series = text_series.str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)  # Eliminar caracteres especiales\n",
    "    text_series = text_series.str.replace(r'\\s+', ' ', regex=True)  # Reemplazar múltiples espacios por uno\n",
    "    return text_series.str.lower().str.strip()\n",
    "\n",
    "# Cargar datasets\n",
    "train_data = pd.read_csv(\"divisonDatos/train_data.csv\", sep=\";\")\n",
    "val_data = pd.read_csv(\"divisonDatos/val_data.csv\", sep=\";\")\n",
    "test_data = pd.read_csv(\"divisonDatos/test_data.csv\", sep=\";\")\n",
    "\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Label, Texto]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "resultado = test_data[test_data['Texto'].str.contains(\"Ecuador\", na=False)]\n",
    "\n",
    "# Si quieres ignorar mayúsculas/minúsculas en la búsqueda:\n",
    "resultado_case_insensitive = test_data[test_data['Texto'].str.contains(\"Ecuador\", case=False, na=False)]\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5000, Loss: 1.0393, Val Loss: 1.0392\n",
      "Epoch 10/5000, Loss: 1.0376, Val Loss: 1.0379\n",
      "Epoch 20/5000, Loss: 1.0368, Val Loss: 1.0372\n",
      "Epoch 30/5000, Loss: 1.0363, Val Loss: 1.0367\n",
      "Epoch 40/5000, Loss: 1.0358, Val Loss: 1.0363\n",
      "Epoch 50/5000, Loss: 1.0355, Val Loss: 1.0360\n",
      "Epoch 60/5000, Loss: 1.0351, Val Loss: 1.0356\n",
      "Epoch 70/5000, Loss: 1.0348, Val Loss: 1.0354\n",
      "Epoch 80/5000, Loss: 1.0345, Val Loss: 1.0351\n",
      "Epoch 90/5000, Loss: 1.0343, Val Loss: 1.0349\n",
      "Epoch 100/5000, Loss: 1.0340, Val Loss: 1.0346\n",
      "Epoch 110/5000, Loss: 1.0338, Val Loss: 1.0344\n",
      "Epoch 120/5000, Loss: 1.0336, Val Loss: 1.0342\n",
      "Epoch 130/5000, Loss: 1.0334, Val Loss: 1.0341\n",
      "Epoch 140/5000, Loss: 1.0332, Val Loss: 1.0339\n",
      "Epoch 150/5000, Loss: 1.0330, Val Loss: 1.0337\n",
      "Epoch 160/5000, Loss: 1.0329, Val Loss: 1.0336\n",
      "Epoch 170/5000, Loss: 1.0327, Val Loss: 1.0334\n",
      "Epoch 180/5000, Loss: 1.0326, Val Loss: 1.0333\n",
      "Epoch 190/5000, Loss: 1.0324, Val Loss: 1.0331\n",
      "Epoch 200/5000, Loss: 1.0323, Val Loss: 1.0330\n",
      "Epoch 210/5000, Loss: 1.0321, Val Loss: 1.0329\n",
      "Epoch 220/5000, Loss: 1.0320, Val Loss: 1.0327\n",
      "Epoch 230/5000, Loss: 1.0319, Val Loss: 1.0326\n",
      "Epoch 240/5000, Loss: 1.0317, Val Loss: 1.0325\n",
      "Epoch 250/5000, Loss: 1.0316, Val Loss: 1.0324\n",
      "Epoch 260/5000, Loss: 1.0315, Val Loss: 1.0323\n",
      "Epoch 270/5000, Loss: 1.0314, Val Loss: 1.0321\n",
      "Epoch 280/5000, Loss: 1.0313, Val Loss: 1.0320\n",
      "Epoch 290/5000, Loss: 1.0311, Val Loss: 1.0319\n",
      "Epoch 300/5000, Loss: 1.0310, Val Loss: 1.0318\n",
      "Epoch 310/5000, Loss: 1.0309, Val Loss: 1.0317\n",
      "Epoch 320/5000, Loss: 1.0308, Val Loss: 1.0316\n",
      "Epoch 330/5000, Loss: 1.0307, Val Loss: 1.0315\n",
      "Epoch 340/5000, Loss: 1.0306, Val Loss: 1.0314\n",
      "Epoch 350/5000, Loss: 1.0305, Val Loss: 1.0314\n",
      "Epoch 360/5000, Loss: 1.0304, Val Loss: 1.0313\n",
      "Epoch 370/5000, Loss: 1.0304, Val Loss: 1.0312\n",
      "Epoch 380/5000, Loss: 1.0303, Val Loss: 1.0311\n",
      "Epoch 390/5000, Loss: 1.0302, Val Loss: 1.0310\n",
      "Epoch 400/5000, Loss: 1.0301, Val Loss: 1.0309\n",
      "Epoch 410/5000, Loss: 1.0300, Val Loss: 1.0308\n",
      "Epoch 420/5000, Loss: 1.0299, Val Loss: 1.0308\n",
      "Epoch 430/5000, Loss: 1.0298, Val Loss: 1.0307\n",
      "Epoch 440/5000, Loss: 1.0298, Val Loss: 1.0306\n",
      "Epoch 450/5000, Loss: 1.0297, Val Loss: 1.0305\n",
      "Epoch 460/5000, Loss: 1.0296, Val Loss: 1.0305\n",
      "Epoch 470/5000, Loss: 1.0295, Val Loss: 1.0304\n",
      "Epoch 480/5000, Loss: 1.0295, Val Loss: 1.0303\n",
      "Epoch 490/5000, Loss: 1.0294, Val Loss: 1.0303\n",
      "Epoch 500/5000, Loss: 1.0293, Val Loss: 1.0302\n",
      "Epoch 510/5000, Loss: 1.0292, Val Loss: 1.0301\n",
      "Epoch 520/5000, Loss: 1.0292, Val Loss: 1.0301\n",
      "Epoch 530/5000, Loss: 1.0291, Val Loss: 1.0300\n",
      "Epoch 540/5000, Loss: 1.0291, Val Loss: 1.0299\n",
      "Epoch 550/5000, Loss: 1.0290, Val Loss: 1.0299\n",
      "Epoch 560/5000, Loss: 1.0289, Val Loss: 1.0298\n",
      "Epoch 570/5000, Loss: 1.0288, Val Loss: 1.0297\n",
      "Epoch 580/5000, Loss: 1.0288, Val Loss: 1.0297\n",
      "Epoch 590/5000, Loss: 1.0287, Val Loss: 1.0296\n",
      "Epoch 600/5000, Loss: 1.0287, Val Loss: 1.0296\n",
      "Epoch 610/5000, Loss: 1.0286, Val Loss: 1.0295\n",
      "Epoch 620/5000, Loss: 1.0285, Val Loss: 1.0294\n",
      "Epoch 630/5000, Loss: 1.0285, Val Loss: 1.0294\n",
      "Epoch 640/5000, Loss: 1.0284, Val Loss: 1.0293\n",
      "Epoch 650/5000, Loss: 1.0284, Val Loss: 1.0293\n",
      "Epoch 660/5000, Loss: 1.0283, Val Loss: 1.0292\n",
      "Epoch 670/5000, Loss: 1.0283, Val Loss: 1.0292\n",
      "Epoch 680/5000, Loss: 1.0282, Val Loss: 1.0291\n",
      "Epoch 690/5000, Loss: 1.0281, Val Loss: 1.0290\n",
      "Epoch 700/5000, Loss: 1.0281, Val Loss: 1.0290\n",
      "Epoch 710/5000, Loss: 1.0280, Val Loss: 1.0289\n",
      "Epoch 720/5000, Loss: 1.0280, Val Loss: 1.0289\n",
      "Epoch 730/5000, Loss: 1.0279, Val Loss: 1.0288\n",
      "Epoch 740/5000, Loss: 1.0279, Val Loss: 1.0288\n",
      "Epoch 750/5000, Loss: 1.0278, Val Loss: 1.0287\n",
      "Epoch 760/5000, Loss: 1.0278, Val Loss: 1.0287\n",
      "Epoch 770/5000, Loss: 1.0277, Val Loss: 1.0286\n",
      "Epoch 780/5000, Loss: 1.0277, Val Loss: 1.0286\n",
      "Epoch 790/5000, Loss: 1.0276, Val Loss: 1.0286\n",
      "Epoch 800/5000, Loss: 1.0276, Val Loss: 1.0285\n",
      "Epoch 810/5000, Loss: 1.0275, Val Loss: 1.0285\n",
      "Epoch 820/5000, Loss: 1.0275, Val Loss: 1.0284\n",
      "Epoch 830/5000, Loss: 1.0274, Val Loss: 1.0284\n",
      "Epoch 840/5000, Loss: 1.0274, Val Loss: 1.0283\n",
      "Epoch 850/5000, Loss: 1.0273, Val Loss: 1.0283\n",
      "Epoch 860/5000, Loss: 1.0273, Val Loss: 1.0282\n",
      "Epoch 870/5000, Loss: 1.0273, Val Loss: 1.0282\n",
      "Epoch 880/5000, Loss: 1.0272, Val Loss: 1.0281\n",
      "Epoch 890/5000, Loss: 1.0272, Val Loss: 1.0281\n",
      "Epoch 900/5000, Loss: 1.0271, Val Loss: 1.0281\n",
      "Epoch 910/5000, Loss: 1.0271, Val Loss: 1.0280\n",
      "Epoch 920/5000, Loss: 1.0270, Val Loss: 1.0280\n",
      "Epoch 930/5000, Loss: 1.0270, Val Loss: 1.0279\n",
      "Epoch 940/5000, Loss: 1.0269, Val Loss: 1.0279\n",
      "Epoch 950/5000, Loss: 1.0269, Val Loss: 1.0279\n",
      "Epoch 960/5000, Loss: 1.0269, Val Loss: 1.0278\n",
      "Epoch 970/5000, Loss: 1.0268, Val Loss: 1.0278\n",
      "Epoch 980/5000, Loss: 1.0268, Val Loss: 1.0277\n",
      "Epoch 990/5000, Loss: 1.0267, Val Loss: 1.0277\n",
      "Epoch 1000/5000, Loss: 1.0267, Val Loss: 1.0277\n",
      "Epoch 1010/5000, Loss: 1.0267, Val Loss: 1.0276\n",
      "Epoch 1020/5000, Loss: 1.0266, Val Loss: 1.0276\n",
      "Epoch 1030/5000, Loss: 1.0266, Val Loss: 1.0275\n",
      "Epoch 1040/5000, Loss: 1.0265, Val Loss: 1.0275\n",
      "Epoch 1050/5000, Loss: 1.0265, Val Loss: 1.0275\n",
      "Epoch 1060/5000, Loss: 1.0265, Val Loss: 1.0274\n",
      "Epoch 1070/5000, Loss: 1.0264, Val Loss: 1.0274\n",
      "Epoch 1080/5000, Loss: 1.0264, Val Loss: 1.0274\n",
      "Epoch 1090/5000, Loss: 1.0264, Val Loss: 1.0273\n",
      "Epoch 1100/5000, Loss: 1.0263, Val Loss: 1.0273\n",
      "Epoch 1110/5000, Loss: 1.0263, Val Loss: 1.0272\n",
      "Epoch 1120/5000, Loss: 1.0262, Val Loss: 1.0272\n",
      "Epoch 1130/5000, Loss: 1.0262, Val Loss: 1.0272\n",
      "Epoch 1140/5000, Loss: 1.0262, Val Loss: 1.0271\n",
      "Epoch 1150/5000, Loss: 1.0261, Val Loss: 1.0271\n",
      "Epoch 1160/5000, Loss: 1.0261, Val Loss: 1.0271\n",
      "Epoch 1170/5000, Loss: 1.0261, Val Loss: 1.0270\n",
      "Epoch 1180/5000, Loss: 1.0260, Val Loss: 1.0270\n",
      "Epoch 1190/5000, Loss: 1.0260, Val Loss: 1.0270\n",
      "Epoch 1200/5000, Loss: 1.0260, Val Loss: 1.0269\n",
      "Early stopping en la época 1210\n",
      "Mejor umbral encontrado: 0.5000\n",
      "Evaluación en validación: Acc=0.7403, F1=0.7646, Precisión=0.7151, Recall=0.8215\n",
      "Evaluación en test:      Acc=0.7290, F1=0.7490, Precisión=0.6921, Recall=0.8162\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (accuracy_score, f1_score, \n",
    "                             precision_score, recall_score, \n",
    "                             confusion_matrix, ConfusionMatrixDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 1) Lectura y Preprocesamiento de Datos\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# EJEMPLO: supongamos que ya tienes 3 dataframes: train_data, val_data, test_data\n",
    "# con columnas [\"Texto\", \"Label\"]. Cada uno es un DataFrame de pandas.\n",
    "\n",
    "# Por ejemplo (placeholder):\n",
    "# train_data = pd.read_csv(\"train.csv\")\n",
    "# val_data   = pd.read_csv(\"val.csv\")\n",
    "# test_data  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Asegúrate de que en train_data, val_data, test_data existan columnas\n",
    "# \"Texto\" (string) y \"Label\" (0 o 1).\n",
    "\n",
    "# Función de preprocesamiento (básica: lower y strip). Mejórala según necesites.\n",
    "def preprocess_text(series):\n",
    "    \"\"\"\n",
    "    Recibe una Series de pandas con texto y retorna otra Series preprocessada.\n",
    "    \"\"\"\n",
    "    return series.str.lower().str.strip()\n",
    "\n",
    "# Aplica la función de preprocesamiento a las columnas de texto\n",
    "train_data['Texto'] = preprocess_text(train_data['Texto'])\n",
    "val_data['Texto']   = preprocess_text(val_data['Texto'])\n",
    "test_data['Texto']  = preprocess_text(test_data['Texto'])\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 2) Vectorización con TF-IDF\n",
    "# --------------------------------------------------------------------------------------\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=30000, \n",
    "    ngram_range=(1, 2), \n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_data['Texto']).toarray()\n",
    "X_val   = vectorizer.transform(val_data['Texto']).toarray()\n",
    "X_test  = vectorizer.transform(test_data['Texto']).toarray()\n",
    "\n",
    "y_train = train_data['Label'].values\n",
    "y_val   = val_data['Label'].values\n",
    "y_test  = test_data['Label'].values\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 3) Cálculo de pesos de clase y conversión a tensores\n",
    "# --------------------------------------------------------------------------------------\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weights *= 1.5  # Ajuste manual\n",
    "# class_weights es un array, lo convertimos a tensor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Convertir features y labels a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_val_tensor   = torch.tensor(X_val,   dtype=torch.float32).to(device)\n",
    "X_test_tensor  = torch.tensor(X_test,  dtype=torch.float32).to(device)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_val_tensor   = torch.tensor(y_val,   dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_test_tensor  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 4) Creación de DataLoaders\n",
    "# --------------------------------------------------------------------------------------\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 5) Definición del Modelo de Regresión Logística en PyTorch\n",
    "# --------------------------------------------------------------------------------------\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Activación sigmoide para salida binaria\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "# Inicializar el modelo\n",
    "input_dim = X_train.shape[1]\n",
    "model = LogisticRegressionModel(input_dim).to(device)\n",
    "\n",
    "# Función auxiliar para inicializar pesos\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 6) Definir la función de pérdida (BCELoss sin reducción, para aplicar pesos)\n",
    "# --------------------------------------------------------------------------------------\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 7) Implementación manual de Adagrad\n",
    "# --------------------------------------------------------------------------------------\n",
    "class ManualAdagrad:\n",
    "    def __init__(self, model_parameters, lr=1e-4, weight_decay=1e-2, eps=1e-8):\n",
    "        self.params = list(model_parameters)  # lista de parámetros del modelo\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.eps = eps\n",
    "        \n",
    "        # Diccionario para almacenar la suma de cuadrados de gradientes de cada parámetro\n",
    "        self.accumulators = {}\n",
    "        for p in self.params:\n",
    "            # Igual shape que p.data, inicializado a cero\n",
    "            self.accumulators[p] = torch.zeros_like(p.data, device=p.data.device)\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Actualiza los parámetros según la regla de Adagrad.\"\"\"\n",
    "        for p in self.params:\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            \n",
    "            # Aplicar regularización L2 directamente al gradiente\n",
    "            p.grad.data.add_(p.data, alpha=self.weight_decay)\n",
    "\n",
    "            # Sumar el cuadrado del gradiente al acumulador\n",
    "            self.accumulators[p] += p.grad.data ** 2\n",
    "\n",
    "            # Denominador para la actualización\n",
    "            denom = torch.sqrt(self.accumulators[p]) + self.eps\n",
    "            \n",
    "            # Regla de Adagrad\n",
    "            p.data = p.data - self.lr * (p.grad.data / denom)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Pone a cero los gradientes.\"\"\"\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "\n",
    "# Creamos nuestro \"optimizador\" Adagrad manual\n",
    "manual_adagrad = ManualAdagrad(model.parameters(), lr=0.0001, weight_decay=0.01, eps=1e-8)\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 8) Early Stopping\n",
    "# --------------------------------------------------------------------------------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=30, delta=0.0001):\n",
    "        \"\"\"\n",
    "        :param patience: cuántas épocas consecutivas se permite que no mejore la val_loss.\n",
    "        :param delta: pequeña mejora mínima considerada.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.stop_training = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop_training = True\n",
    "        return self.stop_training\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 9) Función de entrenamiento con Adagrad manual\n",
    "# --------------------------------------------------------------------------------------\n",
    "def train_model_manual_adagrad(model, train_loader, criterion, manual_adagrad, \n",
    "                               val_loader, class_weights, n_epochs=2000):\n",
    "    \"\"\"\n",
    "    Entrena el modelo usando una implementación manual de Adagrad.\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(patience=30, delta=0.0001)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # -- Modo entrenamiento --\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 1) Reiniciar gradientes\n",
    "            manual_adagrad.zero_grad()\n",
    "\n",
    "            # 2) Forward\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.view(-1, 1)\n",
    "            loss = criterion(outputs, labels)  # BCELoss con shape (batch_size,)\n",
    "\n",
    "            # Aplicar pesos de clase\n",
    "            weights = torch.where(labels == 1, class_weights[1], class_weights[0])\n",
    "            loss = (loss * weights).mean()\n",
    "\n",
    "            # 3) Backward\n",
    "            loss.backward()\n",
    "\n",
    "            # 4) Actualizar parámetros con Adagrad manual\n",
    "            manual_adagrad.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # -- Validación --\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                labels = labels.view(-1, 1)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                weights = torch.where(labels == 1, class_weights[1], class_weights[0])\n",
    "                val_loss += (loss * weights).mean().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Early stopping\n",
    "        if early_stopping(avg_val_loss):\n",
    "            print(f\"Early stopping en la época {epoch}\")\n",
    "            break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch}/{n_epochs}, Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        model.train()  # volver a modo entrenamiento\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 10) Entrenar el modelo\n",
    "# --------------------------------------------------------------------------------------\n",
    "train_model_manual_adagrad(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    criterion=criterion,\n",
    "    manual_adagrad=manual_adagrad,\n",
    "    val_loader=val_loader,\n",
    "    class_weights=class_weights,\n",
    "    n_epochs=5000\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 11) Ajustar umbral dinámicamente y evaluar\n",
    "# --------------------------------------------------------------------------------------\n",
    "def evaluate_model(model, data_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions = (outputs >= threshold).float()\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    y_true = np.array(y_true).flatten()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    return acc, f1, precision, recall\n",
    "\n",
    "def find_best_threshold(model, val_loader):\n",
    "    thresholds = np.linspace(0.1, 0.9, 100)\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        acc, f1, precision, recall = evaluate_model(model, val_loader, threshold=threshold)\n",
    "        # Si precisión y recall son > 0.75 y f1 es mejor que lo visto hasta ahora, actualizamos\n",
    "        if precision > 0.75 and recall > 0.75 and f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold\n",
    "\n",
    "best_threshold = find_best_threshold(model, val_loader)\n",
    "print(f\"Mejor umbral encontrado: {best_threshold:.4f}\")\n",
    "\n",
    "# Evaluación en validación\n",
    "acc, f1, precision, recall = evaluate_model(model, val_loader, threshold=best_threshold)\n",
    "print(f\"Evaluación en validación: Acc={acc:.4f}, F1={f1:.4f}, Precisión={precision:.4f}, Recall={recall:.4f}\")\n",
    "\n",
    "# Evaluación en test\n",
    "acc, f1, precision, recall = evaluate_model(model, test_loader, threshold=best_threshold)\n",
    "print(f\"Evaluación en test:      Acc={acc:.4f}, F1={f1:.4f}, Precisión={precision:.4f}, Recall={recall:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 12) Visualizar matriz de confusión en Test\n",
    "# --------------------------------------------------------------------------------------\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "y_pred, y_true = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs >= best_threshold).float()\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "plot_confusion_matrix(np.array(y_true).flatten(), np.array(y_pred).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
